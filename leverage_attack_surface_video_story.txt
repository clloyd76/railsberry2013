$ cd src/hacking/railsberry2013; $ rvm use 1.9.3@codesake; gem list gengiscan; gengiscan http://localhost:4567\; "A ruby powered web application... served by WEBrick (remember, we don't know nothing about it every information is a step forward to find a way to exploit it) no generator meta tag, may be not a CMS. Now we will ask for robots.txt. Let's see if we can find something useful; links -r http://localhost:4567; "Wow it seems that /backend URL that it was intented to be Disallowed it's opened to the world. We will check it later; ll; less test_case_dir_wordlist.txt; "This is a very tiniy dictionary with well known URLs, we will use to bruteforce the website the site checking if some of those are there... the bigger is the dictionary better will be the results; links -b test_case_dir_wordlist.txt http://localhost:4567; We discovered that our target: 1) is served by WEBrick 2) it's an application written in Ruby (can't say nothing about the framework at the moment) 3) there is a /backend url intended to be disallowed but opened and other 2 dirs that redirect me to login page 4) there is a /users URL... maybe a website user directory?
